# ActionErrorReporter

This GitHub workflow harnesses the capabilities of Large Language Models (LLMs)
to automate identification and triage of CI/CD processes initiated by Pull
Request events and/or status check errors. These failures usually don't raise
any notifications and reasons are buried in logs which requires manual
investigation by browsing github action logs.

This Github workflow aims to help reduce / eliminate time to triage CI/CD
failures by having LLM doing the triage for us: monitor CI/CD logs and notify by
searching and summarizing the CI/CD failures and also tries to suggest the fix.

An example of steps that could be fully automated by this workflow:

- dbt PR are blocked from merging due to failing status checks
- found out that the build CI/CD fails
- go to github action tab and find the latest runs among runs generated by other
  PRs
- find the steps with failures, read through logs
- found out that author forgot to add some sources
- notify author / comment in PR

# Prerequisites

- CI/CD workflow(s) that you want to monitor and analyze logs for errors.
  - Currently supports only workflows that are triggered by Pull Request events.
- An implementation of `workflow_run` workflow that triggers the LLM action.
- An OpenAI API key with access to GPT chat completion endpoints. Ask in
  `#ds_ai` if you need an API key.
- SHA of the tag you want to use.

# Usage

Create a workflow with `workflow_run` so that it triggers the analysis as soons
as the workflow you want to monitor completes.

```yaml
name: LLM Action Error Reporter
# this workflow runs by listening to the completion of the workflow(s) specified in the `workflows` field
# workaround while waiting for https://github.com/actions/runner/issues/886 (gh run view can't run in currently running workflow)
on:
  workflow_run:
    # ***IMPORTANT***
    # "CICD Process" is a placeholder for the workflow name that you want to monitor
    workflows: ["CICD Process"]
    # in this case, it listens to the completion state regardless of the outcome as we want to listen to both failure and success
    types:
      - completed

jobs:
  analyze_logs:
    runs-on: ubuntu-latest
    # permissions required to run this job
    permissions:
      contents: read
      pull-requests: write
      repository-projects: read
      actions: read
    steps:
      - name: Analyze logs
        uses: smartcontractkit/.github/actions/llm-action-error-reporter@[SHA] # points to a specific tag like llm-action-error-reporter@0.3.0
        with:
          # GitHub token used to fetch the PR diff and create a new PR comment.
          # ${{ secrets.GITHUB_TOKEN }} will be sufficient.
          gh-token: ""
          # "The conclusion status of the parent workflow: either 'success' or 'failure'"
          # you would usually supply '${{ github.event.workflow_run.conclusion }}' here
          parent_workflow_conclusion: ""
          # skips reporting success on PR if the parent workflow hasn't failed to reduce noise
          # does not prevent editing of existing failure reports
          # default is false
          skip-on-success: [true/false]
          # The maximum number of log lines to process per job
          # defined by gh action log format: [job-name] [step-name] [log-line]
          # default is 500
          log-lines-limit: ""
          # OpenAI model to use for PR description generation. Defaults to 'gpt-3.5-turbo-0125'.
          # If your repository contains complex logic or expects large diffs, use 'gpt-4-turbo-2024-04-09' or newer.
          # Learn more at: https://platform.openai.com/docs/models/overview
          openai-model: ""
          # OpenAI API Key, used to generate PR descriptions using the GPT model.
          # Needs to have access to the chat-completion endpoints
          # Example: ${{ secrets.OPENAI_API_KEY }}
          openai-api-key: ""
          # ref to smartcontractkit/.github repository to load the prompt from. Defaults to main.
          # Usually used during development.
          workflow-ref: ""
```

# Configuration Example

```yaml
jobs:
  analyze_logs:
    runs-on: ubuntu-latest
    # permissions required to run this job
    permissions:
      contents: read
      pull-requests: write
      repository-projects: read
      actions: read
    steps:
      - name: Analyze logs
        with:
          # state of the workflow that evoked this workflow
          parent-workflow-conclusion:
            ${{ github.event.workflow_run.conclusion }}
          # skips reporting success on PR if the parent workflow hasn't failed to reduce noise
          # does not prevent editing of existing failure reports
          # default is false
          skip-on-success: true
          # The maximum number of log lines to process per job
          # defined by gh action log format: [job-name] [step-name] [log-line]
          # default is 500
          log-lines-limit: 300
          gh-token: ${{ github.token }}
          openai-model: "gpt-4o-2024-05-13"
          openai-api-key: ${{ secrets.OPENAI_API_KEY }}
```

# CLI tool

The AER also comes in CLI flavor, where you can pipe log files generated during
your local development to receive similar analysis reports, simply with:

```bash
# requires export OPENAI_API_KEY=[apikey]
# may hallucinate if log doesn't actually contains error
cat logfile.log | aer.sh
```
